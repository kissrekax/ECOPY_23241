{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Az osztály(oka)t mentsd a __src/linear_regression__ modul __LinearRegressions.py__ fájljába\n",
    "Használható modulok: _pathlib, pandas, typing, str, numpy_, valamint a _scipy.stats t_ és _f_ osztályai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"from pandas import Series\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_formatted_code = \"from pandas import Series\\n\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.689205200Z",
     "start_time": "2023-11-14T10:12:32.178114Z"
    }
   },
   "id": "7066ec7a2294843b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.735110800Z",
     "start_time": "2023-11-14T10:12:33.688113400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"from pathlib import Path\\n\\nimport numpy as np\\nimport pandas as pd\";\n                var nbb_formatted_code = \"from pathlib import Path\\n\\nimport numpy as np\\nimport pandas as pd\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"datalib = Path.cwd().parent.joinpath('data')\";\n                var nbb_formatted_code = \"datalib = Path.cwd().parent.joinpath(\\\"data\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.775111200Z",
     "start_time": "2023-11-14T10:12:33.733149300Z"
    }
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adatelőkészítés (0 pont)\n",
    "1., Olvasd be a data mappa __sp500.parquet__ nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "2., Olvasd be az __ff_factors.parquet__ fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a __'Date' elsődleges kulcs__ alapján.\n",
    "4., Készíts egy új __'Excess Return'__ nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "5., <u>Rendezd sorba dátum szerint az adatokat</u>, majd generálj egy új oszlopot (__'ex_ret_1'__), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a <u>következő időszaki Excess Return</u> érték. \n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer <u>törlöd az össze olyan sort</u>, amely az __'ex_ret_1' oszlopban hiányos__, majd ezt követően, törlöd az összes olyan sort, ami a __'HML' oszlopban hiányos__.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad5a013c358987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. feladat segítség\n",
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. feladat segítség\n",
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "            ex_ret_1\nDate                \n2000-01-31  0.023796\n2000-02-29 -0.074223\n2000-03-31 -0.174575\n2000-05-31 -0.288383\n2000-06-30 -0.218396\n...              ...\n2022-05-31 -0.122459\n2022-06-30 -0.079615\n2022-08-31 -0.127622\n2022-09-30 -0.116451\n2022-10-31 -0.086595\n\n[194 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ex_ret_1</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-01-31</th>\n      <td>0.023796</td>\n    </tr>\n    <tr>\n      <th>2000-02-29</th>\n      <td>-0.074223</td>\n    </tr>\n    <tr>\n      <th>2000-03-31</th>\n      <td>-0.174575</td>\n    </tr>\n    <tr>\n      <th>2000-05-31</th>\n      <td>-0.288383</td>\n    </tr>\n    <tr>\n      <th>2000-06-30</th>\n      <td>-0.218396</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-05-31</th>\n      <td>-0.122459</td>\n    </tr>\n    <tr>\n      <th>2022-06-30</th>\n      <td>-0.079615</td>\n    </tr>\n    <tr>\n      <th>2022-08-31</th>\n      <td>-0.127622</td>\n    </tr>\n    <tr>\n      <th>2022-09-30</th>\n      <td>-0.116451</td>\n    </tr>\n    <tr>\n      <th>2022-10-31</th>\n      <td>-0.086595</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sp500 = pd.read_parquet('/Users/kissr/Downloads/Programming/Python/ECOPY_23241/data/sp500.parquet',\n",
    "                        engine='fastparquet')\n",
    "ff_factors = pd.read_parquet('/Users/kissr/Downloads/Programming/Python/ECOPY_23241/data/ff_factors.parquet',\n",
    "                             engine='fastparquet')\n",
    "\n",
    "# 3\n",
    "merged_df = pd.merge(sp500, ff_factors, on='Date', how='left')\n",
    "\n",
    "# 4\n",
    "merged_df['Excess Return'] = merged_df['Monthly Returns'] - merged_df['RF']\n",
    "\n",
    "# 5\n",
    "merged_df = merged_df.sort_values(by=['Symbol', 'Date'])\n",
    "merged_df['ex_ret_1'] = merged_df.groupby('Symbol')['Excess Return'].shift(-1)\n",
    "\n",
    "# 6\n",
    "merged_df = merged_df.dropna(subset=['ex_ret_1'])\n",
    "merged_df = merged_df.dropna(subset=['HML'])\n",
    "\n",
    "# 7\n",
    "amazon_df = merged_df[merged_df['Symbol'] == 'AMZN']\n",
    "amazon_df = amazon_df.drop(columns=['Symbol'])\n",
    "amazon_df\n",
    "\n",
    "y = amazon_df[['ex_ret_1']]\n",
    "x = amazon_df[['Mkt-RF', 'SMB', 'HML']]\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:48:33.645987500Z",
     "start_time": "2023-11-15T19:48:33.454322500Z"
    }
   },
   "id": "4959bed9ce5596ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modell összeállítás (7 pont)\n",
    "\n",
    "A meglévő adatokból válaszd ki a __Amazon részvényhez tartozó sorokat (AMZN)__ és töröld a tickereket tartalmazó oszlopot. <u>Amennyiben működött, önellenőrzésre használhatod a legutóbbi zárthelyin írt osztályt is.</u>\n",
    "\n",
    "7., Készíts egy új __LinearRegressionGLS__ elnevezésű osztályt. Definiáld benne a __\\_\\_init\\_\\___ nevű függvényt, amely bemenetként 2 DataFrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (__left_hand_side__), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (__right_hand_side__).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy __fit__ metódussal, ami Feasible GLS elvű becslést hajt végre. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között, amely az első változó legyen. <u>__(numpy.linalg.lstsq() nem használható)__</u>\n",
    "\n",
    "9., Egészítsd ki az osztályt egy __get_params__ metódussal, ami visszaadja a becsült modell béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen __Beta coefficients__. \n",
    "\n",
    "10., Egészítsd ki az osztályt egy __get_pvalues__ metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: __P-values for the corresponding coefficients__. A p értéket t-statisztika alapján számold ki. A p-érték kiszámításánál figyelj alkalmazd a <u>min(value, 1-value) * 2</u> képletet.\n",
    "\n",
    "11., Egészítsd ki az osztályt egy __get_wald_test_result__ metódussal, ami visszaadja a bemeneti restrikciós mátrix alapján számolt F és p értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Wald: wald_value, p-value: p_value__, ahol az wald_value és p_value helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. A függvény bemenete során feltételezzük, hogy r minden eleme 0, R-t listák listája formában adjuk át. A Wald statisztika p értékét az előző feladathoz hasonlóan számold ki, de figyelj, hogy a <u>teszt 1 oldalú</u>.\n",
    "\n",
    "12., Egészítse ki az osztályt egy __get_model_goodness_values__ metódussal, ami visszadja a centrált és a módosított R-négyzet értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Centered R-squared: crs, Adjusted R-squared: ars__, ahol crs és ars helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. <u>Ha a regresszorok számába eredetileg beleszámítottad a konstanst is, akkor a módosított R-négyzet számítás nevezőjében nincs szükség a __-1__-es tagra</u>."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1888d0ef54d4b2c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Feasible GLS becslésének a menete__:\n",
    "1.) A bementeni adatok alapján OLS elven becsüld meg a változók együtthatóit.\n",
    "2.) Számold ki a hibatagokat\n",
    "3.) A hibatagoknak vedd a négyzetét\n",
    "4.) Becsülj egy új modellt, ahol a bal oldali változó a hibatag négyzetének logaritmusa, míg a jobboldali változók az eredeti jobb oldali változóid.\n",
    "5.) Számold ki a becsült értékeket (logaritmikus négyzetes hibákat) és vedd őket az e kitevőjeként, majd vonj belőlük gyököt.\n",
    "6.) A kapott vektornak vedd elemenként az inverzét és helyezd el egy diagonális mátrix főátlójában őket (np.diag). -> Az így kapott mátrix lesz a V inverz mátrix.\n",
    "7.) A V inverz mátrix felhasználásával becsüld meg a GLS regresszió paramétereit\n",
    "8.) Egyszerűsítés képpen számold ki a hibatagot a nem transzformált Y és X mátrixok és GLS paraméterek segítségével."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e27e69ded63aa7b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "__FGLS R^2 számításhoz__:\n",
    "SSR =  Y\\^T * V\\^(-1) * X * (X\\^T * V\\^(-1) * X)\\^(-1) * X\\^T * V\\^(-1) * Y\n",
    "SST = Y\\^T * V\\^(-1) * Y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea8841ea4822005"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearRegressionSM(x,y)\n\u001B[0;32m      8\u001B[0m model_1 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m----> 9\u001B[0m betas \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_params()\n\u001B[0;32m     10\u001B[0m betas\n",
      "File \u001B[1;32m~\\Downloads\\Programming\\Python\\ECOPY_23241\\src\\linear_regression\\LinearRegressions.py:24\u001B[0m, in \u001B[0;36mLinearRegressionSM.get_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     23\u001B[0m     beta_coefficients \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mparams\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mSeries(beta_coefficients, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBeta coefficients\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:386\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[1;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m     name \u001B[38;5;241m=\u001B[39m ibase\u001B[38;5;241m.\u001B[39mmaybe_extract_name(name, data, \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m))\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_empty_data(data) \u001B[38;5;129;01mand\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;66;03m# gh-17261\u001B[39;00m\n\u001B[0;32m    388\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    389\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe default dtype for empty Series will be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    390\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat64\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a future version. Specify a dtype explicitly \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    393\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    394\u001B[0m         )\n\u001B[0;32m    395\u001B[0m         \u001B[38;5;66;03m# uncomment the line below when removing the FutureWarning\u001B[39;00m\n\u001B[0;32m    396\u001B[0m         \u001B[38;5;66;03m# dtype = np.dtype(object)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\construction.py:877\u001B[0m, in \u001B[0;36mis_empty_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    875\u001B[0m is_none \u001B[38;5;241m=\u001B[39m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    876\u001B[0m is_list_like_without_dtype \u001B[38;5;241m=\u001B[39m is_list_like(data) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 877\u001B[0m is_simple_empty \u001B[38;5;241m=\u001B[39m is_list_like_without_dtype \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data\n\u001B[0;32m    878\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_none \u001B[38;5;129;01mor\u001B[39;00m is_simple_empty\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:1527\u001B[0m, in \u001B[0;36mNDFrame.__nonzero__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__nonzero__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1528\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe truth value of a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is ambiguous. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1529\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1530\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:28:13.708953600Z",
     "start_time": "2023-11-15T19:28:09.891212Z"
    }
   },
   "id": "679dfc102cbafe7c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert alfa, already exists",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 79\u001B[0m\n\u001B[0;32m     76\u001B[0m         adj_r2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m r2), \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     77\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCentered R-squared: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mr2\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Adjusted R-squared: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00madj_r2\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 79\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearRegressionGLS(y,x)\n\u001B[0;32m     80\u001B[0m model\u001B[38;5;241m.\u001B[39my_pred\n",
      "Cell \u001B[1;32mIn[18], line 12\u001B[0m, in \u001B[0;36mLinearRegressionGLS.__init__\u001B[1;34m(self, left_hand_side, right_hand_side)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft_hand_side \u001B[38;5;241m=\u001B[39m left_hand_side\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_hand_side \u001B[38;5;241m=\u001B[39m right_hand_side\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_hand_side\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malfa\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4817\u001B[0m, in \u001B[0;36mDataFrame.insert\u001B[1;34m(self, loc, column, value, allow_duplicates)\u001B[0m\n\u001B[0;32m   4811\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   4812\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot specify \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mallow_duplicates=True\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4813\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mself.flags.allows_duplicate_labels\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is False.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4814\u001B[0m     )\n\u001B[0;32m   4815\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_duplicates \u001B[38;5;129;01mand\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m   4816\u001B[0m     \u001B[38;5;66;03m# Should this be a different kind of error??\u001B[39;00m\n\u001B[1;32m-> 4817\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot insert \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, already exists\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   4818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(loc, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m   4819\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloc must be int\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: cannot insert alfa, already exists"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\n",
    "class LinearRegressionGLS:\n",
    "\n",
    "    def __init__(self, left_hand_side, right_hand_side):\n",
    "        self.left_hand_side = left_hand_side\n",
    "        self.right_hand_side = right_hand_side\n",
    "        self.right_hand_side.insert(0, 'alfa', 1)\n",
    "        self._model = None\n",
    "\n",
    "    def fit(self):\n",
    "        Y = self.left_hand_side\n",
    "        X = self.right_hand_side\n",
    "        self.XtX = np.dot(np.transpose(self.right_hand_side), self.right_hand_side)\n",
    "        self.XtX_inv = np.linalg.inv(self.XtX)\n",
    "        self.Xty = np.dot(np.transpose(self.right_hand_side), self.left_hand_side)\n",
    "        self.betas = np.dot(self.XtX_inv, self.Xty)\n",
    "        self.residuals = self.left_hand_side - np.dot(self.right_hand_side, self.betas)\n",
    "        self.residuals = self.residuals**2\n",
    "        self.residuals = np.log(self.residuals)\n",
    "        Y_new= self.residuals\n",
    "        X_new = self.right_hand_side\n",
    "        self.XtX = np.dot(np.transpose(self.right_hand_side), self.right_hand_side)\n",
    "        self.XtX_inv = np.linalg.inv(self.XtX)\n",
    "        self.Xty = np.dot(np.transpose(self.right_hand_side), self.residuals)\n",
    "        self.betas = np.dot(self.XtX_inv, self.Xty)\n",
    "        self.residuals_new = self.residuals - np.dot(self.right_hand_side, self.betas)\n",
    "        self.y_pred = self.right_hand_side@self.betas + self.residuals_new\n",
    "        self.y_pred = np.exp(self.y_pred)\n",
    "        self.y_pred = np.sqrt(self.y_pred)\n",
    "        self.y_pred_inv = np.reciprocal(self.y_pred)\n",
    "        self.V = np.diag(self.y_pred_inv)\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_params(self):\n",
    "        Y = self.left_hand_side\n",
    "        X = self.right_hand_side\n",
    "        self.XtX_gls = self.right_hand_side.T@self.V@self.right_hand_side\n",
    "        self.XtX_inv_gls = np.linalg.inv(self.XtX_gls)\n",
    "        self.Xty_gls = self.right_hand_side.T@self.V@self.left_hand_side\n",
    "        self.betas_gls = self.XtX_inv_gls@self.Xty_gls\n",
    "        return pd.Series(self.betas, name='Beta coefficients')\n",
    "\n",
    "    def get_pvalues(self):\n",
    "        self.residuals_gls = self.left_hand_side - self.right_hand_side@self.betas_gls\n",
    "        self.n = len(self.left_hand_side)\n",
    "        self.K = len(self.right_hand_side.columns)\n",
    "        self.df = self.n - self.K\n",
    "        self.variance_gls = self.residuals_gls.T@self.residuals_gls / self.df\n",
    "        self.stderror_gls = np.sqrt(self.variance_gls * np.diag(self.XtX_inv_gls))\n",
    "        self.t_stat_gls = np.divide(self.betas_gls, self.stderror_gls)\n",
    "        term = np.minimum(scipy.stats.t.cdf(self.t_stat_gls, self.df), 1 - scipy.stats.t.cdf(self.t_stat_gls, self.df))\n",
    "        p_values = (term) * 2\n",
    "        return pd.Series(p_values, name='P-values for the corresponding coefficients')\n",
    "\n",
    "    def get_wald_test_result(self, restr_matrix):\n",
    "        term_1 = np.dot(restr_matrix, self.betas)\n",
    "        term_2 = np.dot(np.dot(restr_matrix, self.XtX_inv_gls), np.transpose(restr_matrix))\n",
    "        f_stat = (np.dot(np.transpose(term_1), np.dot(np.linalg.inv(term_2), term_1)) / len(\n",
    "            restr_matrix)) / self.variance_gls\n",
    "        p_value = (1 - scipy.stats.f.cdf(f_stat, len(restr_matrix), self.df))\n",
    "        f_stat.astype(float)\n",
    "        p_value.astype(float)\n",
    "        return f'Wald: {round(f_stat, 3)}, p-value: {round(p_value, 3)}'\n",
    "\n",
    "    def get_model_goodness_values(self):\n",
    "        y_demean = self.left_hand_side - sum(self.left_hand_side) / len(self.left_hand_side)\n",
    "        SST = self.left_hand_side@np.linalg.inv(self.V)@self.left_hand_side\n",
    "        SSE = np.dot(np.transpose(self.residuals_gls), self.residuals_gls)\n",
    "        r2 = round(1 - SSE / SST, 3)\n",
    "        adj_r2 = round(1 - (self.n - 1) / (self.df) * (1 - r2), 3)\n",
    "        return f'Centered R-squared: {r2:.3f}, Adjusted R-squared: {adj_r2:.3f}'\n",
    "    \n",
    "model = LinearRegressionGLS(y,x)\n",
    "model.y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:49:55.051015600Z",
     "start_time": "2023-11-15T19:49:54.856960100Z"
    }
   },
   "id": "e5be24b06cef2eb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
