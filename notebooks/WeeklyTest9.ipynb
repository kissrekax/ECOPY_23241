{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Az osztály(oka)t mentsd a __src/linear_regression__ modul __LinearRegressions.py__ fájljába\n",
    "Használható modulok: _pathlib, pandas, typing, str, numpy, scipy.stats t_ és _norm_, valamint a _scipy.optimize_ _minimize_ osztályai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7066ec7a2294843b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adatelőkészítés (0 pont)\n",
    "1., Olvasd be a data mappa __sp500.parquet__ nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "2., Olvasd be az __ff_factors.parquet__ fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a __'Date' elsődleges kulcs__ alapján.\n",
    "4., Készíts egy új __'Excess Return'__ nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "5., <u>Rendezd sorba dátum szerint az adatokat</u>, majd generálj egy új oszlopot (__'ex_ret_1'__), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a <u>következő időszaki Excess Return</u> érték. \n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer <u>törlöd az össze olyan sort</u>, amely az __'ex_ret_1' oszlopban hiányos__, majd ezt követően, törlöd az összes olyan sort, ami a __'HML' oszlopban hiányos__.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad5a013c358987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. feladat segítség\n",
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. feladat segítség\n",
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.1, 0.1, 0.1, 0.1, 0.1])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "type(x)\n",
    "np.array(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T18:41:26.830437200Z",
     "start_time": "2023-11-22T18:41:26.671474700Z"
    }
   },
   "id": "760e41517a8f96ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modell összeállítás (7 pont)\n",
    "\n",
    "A meglévő adatokból válaszd ki a __Amazon részvényhez tartozó sorokat (AMZN)__ és töröld a tickereket tartalmazó oszlopot. <u>Amennyiben működött, önellenőrzésre használhatod a legutóbbi zárthelyin írt osztályt is.</u>\n",
    "\n",
    "7., Készíts egy új __LinearRegressionML__ elnevezésű osztályt. Definiáld benne a __\\_\\_init\\_\\___ nevű függvényt, amely bemenetként 2 DataFrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (__left_hand_side__), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (__right_hand_side__).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy __fit__ metódussal, ami ML elvű becslést hajt végre. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között, amely az első változó legyen. __A feladatot numerikus optimalizálással old meg, analítikus megoldásra nem ját pont__\n",
    "\n",
    "9., Egészítsd ki az osztályt egy __get_params__ metódussal, ami visszaadja a becsült modell béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen __Beta coefficients__. \n",
    "\n",
    "10., Egészítsd ki az osztályt egy __get_pvalues__ metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: __P-values for the corresponding coefficients__. A p értéket t-statisztika alapján számold ki. A p-érték kiszámításánál figyelj, hogy  alkalmazd a <u>min(value, 1-value) * 2</u> képletet.\n",
    "\n",
    "11., Egészítse ki az osztályt egy __get_model_goodness_values__ metódussal, ami visszadja a centrált és a módosított R-négyzet értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Centered R-squared: crs, Adjusted R-squared: ars__, ahol crs és ars helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. <u>Ha a regresszorok számába eredetileg beleszámítottad a konstanst is, akkor a módosított R-négyzet számítás nevezőjében nincs szükség a __-1__-es tagra</u>."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1888d0ef54d4b2c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kiegészítés:\n",
    "- Mivel a célparaméterek kicsik, a minimalizálás kiinduló értékeit érdemes egységesen, minden paraméter számára __0.1__-re állítani.\n",
    "- Javasolt a __L-BFGS-B__ optimalizáló alkalmazása\n",
    "- Ne felejtsd el, hogy az MLE __variancia becslése torzított__. A kapott eredményeket ennek megfelelően korrigáld."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5636fb7cd43f4897"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def loglikelihood(params, X, Y):\n",
    "    beta = params[:-1]\n",
    "    sigma_squared = params[-1]\n",
    "    n = len(Y)\n",
    "    residuals = Y - np.dot(X, beta)\n",
    "    log_likelihood = -0.5 * n * np.log(2 * np.pi * sigma_squared) - 0.5 * np.sum(residuals**2) / sigma_squared\n",
    "    return -log_likelihood"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T19:33:01.150359700Z",
     "start_time": "2023-11-22T19:33:01.114653600Z"
    }
   },
   "id": "b74aa975a3c02d04"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "amazon_df = pd.read_parquet('/Users/kissr/Downloads/Programming/Python/ECOPY_23241/data/weekly6/toclean.parquet', engine='fastparquet')\n",
    "amazon_df.insert(0, 'alpha', 1)\n",
    "y = amazon_df['ex_ret_1']\n",
    "x = amazon_df[['alpha', 'Mkt-RF', 'SMB', 'HML']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T19:31:59.546846900Z",
     "start_time": "2023-11-22T19:31:59.531529400Z"
    }
   },
   "id": "f51c210ce9f5a788"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m params \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m]\n\u001B[0;32m      3\u001B[0m loglikelihood(params, x, y)\n\u001B[1;32m----> 4\u001B[0m res \u001B[38;5;241m=\u001B[39m scipy\u001B[38;5;241m.\u001B[39moptimize\u001B[38;5;241m.\u001B[39mminimize(loglikelihood(params, x, y), params)\n\u001B[0;32m      5\u001B[0m res\u001B[38;5;241m.\u001B[39mx\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:691\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    689\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_cg(fun, x0, args, jac, callback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 691\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    692\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnewton-cg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    693\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    694\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:1362\u001B[0m, in \u001B[0;36m_minimize_bfgs\u001B[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, **unknown_options)\u001B[0m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maxiter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1360\u001B[0m     maxiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x0) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m200\u001B[39m\n\u001B[1;32m-> 1362\u001B[0m sf \u001B[38;5;241m=\u001B[39m _prepare_scalar_function(fun, x0, jac, args\u001B[38;5;241m=\u001B[39margs, epsilon\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m   1363\u001B[0m                               finite_diff_rel_step\u001B[38;5;241m=\u001B[39mfinite_diff_rel_step)\n\u001B[0;32m   1365\u001B[0m f \u001B[38;5;241m=\u001B[39m sf\u001B[38;5;241m.\u001B[39mfun\n\u001B[0;32m   1366\u001B[0m myfprime \u001B[38;5;241m=\u001B[39m sf\u001B[38;5;241m.\u001B[39mgrad\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:332\u001B[0m, in \u001B[0;36m_prepare_scalar_function\u001B[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001B[0m\n\u001B[0;32m    328\u001B[0m     bounds \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39minf, np\u001B[38;5;241m.\u001B[39minf)\n\u001B[0;32m    330\u001B[0m \u001B[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001B[39;00m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;66;03m# calculation reduces overall function evaluations.\u001B[39;00m\n\u001B[1;32m--> 332\u001B[0m sf \u001B[38;5;241m=\u001B[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001B[0;32m    333\u001B[0m                     finite_diff_rel_step, bounds, epsilon\u001B[38;5;241m=\u001B[39mepsilon)\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sf\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001B[0m, in \u001B[0;36mScalarFunction.__init__\u001B[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m fun_wrapped(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fun_impl \u001B[38;5;241m=\u001B[39m update_fun\n\u001B[1;32m--> 158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fun()\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# Gradient evaluation\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(grad):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 251\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fun_impl()\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[1;34m()\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m fun_wrapped(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m fun(np\u001B[38;5;241m.\u001B[39mcopy(x), \u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "params = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "loglikelihood(params, x, y)\n",
    "res = scipy.optimize.minimize(loglikelihood(params, x, y), params)\n",
    "res.x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T19:34:47.236759500Z",
     "start_time": "2023-11-22T19:34:47.064060100Z"
    }
   },
   "id": "328dc321e8de3989"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
